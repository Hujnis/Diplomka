import os
import unicodedata
import random
from duckduckgo_search import DDGS
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
from bs4 import BeautifulSoup
import re
import instaloader

#___________________________________________________________________________________________________________________
#                                                     DICTIONARY
#___________________________________________________________________________________________________________________


# Z√≠sk√°n√≠ cesty ke slo≈æce, kde je ulo≈æen tento skript
script_dir = os.path.dirname(os.path.abspath(__file__))
txt_path = os.path.join(script_dir, 'czech_names.txt')

# Naƒçten√≠ slovn√≠ku ƒçesk√Ωch jmen ze souboru s o≈°et≈ôen√≠m chyb
try:
    with open(txt_path, 'r', encoding='utf-8') as f:
        name_dictionary = set(line.strip() for line in f if line.strip())
except FileNotFoundError:
    print(f"‚ùåError: Soubor '{txt_path}' nebyl nalezen.")
    name_dictionary = set()
except Exception as e:
    print(f"‚ùåError p≈ôi ƒçten√≠ souboru '{txt_path}': {e}")
    name_dictionary = set()

# U≈æiteƒçn√© pro porovn√°v√°n√≠ jmen s diakritikou i bez n√≠
def remove_diacritics(input_str):
    return ''.join(
        c for c in unicodedata.normalize('NFD', input_str)
        if unicodedata.category(c) != 'Mn'
    )

# Vytvo≈ôen√≠ verze slovn√≠ku jmen bez diakritiky pro snaz≈°√≠ porovn√°n√≠
dictionary_no_diacritics = {
    remove_diacritics(name).lower(): name for name in name_dictionary
}

# Kontrola, zda je dan√© jm√©no ve slovn√≠ku (bez ohledu na velikost p√≠smen, bez diakritiky)
def is_name_in_dictionary(name):
    name_no_diacritics = remove_diacritics(name).lower()
    return name_no_diacritics in dictionary_no_diacritics

# Z√≠sk√°n√≠ spr√°vn√©ho jm√©na ze slovn√≠ku, p≈ôiƒçem≈æ se zachovaj√≠ p≈Øvodn√≠ diakritiky, pokud jsou p≈ô√≠tomny
def get_correct_name(name):
    name_no_diacritics = remove_diacritics(name).lower()
    return dictionary_no_diacritics.get(name_no_diacritics, name)

# Extrahov√°n√≠ jm√©na z e-mailov√© adresy a pokus o jeho porovn√°n√≠ s existuj√≠c√≠m jm√©nem ve slovn√≠ku
def extract_name_from_email(email):
    local_part = email.split('@')[0]
    # Prvn√≠ kontrola: pokud lok√°ln√≠ ƒç√°st obsahuje jm√©no a p≈ô√≠jmen√≠ oddƒõlen√© teƒçkou
    if '.' in local_part:
        name_parts = local_part.split('.')
        if len(name_parts) == 2:
            # Odstranƒõn√≠ diakritiky pro snadnƒõj≈°√≠ porovn√°n√≠
            first_name = remove_diacritics(name_parts[0]).lower()
            last_name = remove_diacritics(name_parts[1]).lower()
            # Kontrola, zda je jm√©no nebo p≈ô√≠jmen√≠ p≈ô√≠tomno ve slovn√≠ku
            if first_name in dictionary_no_diacritics or (last_name and last_name in dictionary_no_diacritics):
                correct_first_name = dictionary_no_diacritics.get(first_name, first_name)
                correct_last_name = dictionary_no_diacritics.get(last_name, last_name)
                potential_name = f"{correct_first_name} {correct_last_name}"
                return potential_name

    # Druh√° kontrola: pokud lok√°ln√≠ ƒç√°st obsahuje pouze jedno jm√©no nebo kombinaci jmen
    local_part_no_diacritics = remove_diacritics(local_part).lower()
    if local_part_no_diacritics in dictionary_no_diacritics:
        correct_name = dictionary_no_diacritics[local_part_no_diacritics]
        return correct_name

    # Pokud ≈æ√°dn√° metoda neuspƒõje, vr√°t√≠me None k indikaci, ≈æe jm√©no nebylo nalezeno
    else:
        return None

#___________________________________________________________________________________________________________________
#                                                     INSTALOADER
#___________________________________________________________________________________________________________________

# Inicializace Instaloaderu
L = instaloader.Instaloader()
scraped_instagrams = set()  # Sada pro ukl√°d√°n√≠ u≈æ scrapnut√Ωch profil≈Ø

def extract_instagram_username(url):
    match = re.search(r"instagram\.com/([^/?#]+)", url)
    return match.group(1) if match else None

# Funkce pro extrakci u≈æivatelsk√©ho jm√©na z Instagram URL
def get_instagram_profile_details(username, retries=2):
    if username in scraped_instagrams:
        print(f"‚úÖ Instagram profil @{username} u≈æ byl scrapnut√Ω, p≈ôeskoƒçeno.")
        return None  # Nepokraƒçujeme, pokud u≈æ m√°me data

    for attempt in range(retries):
        try:
            wait_time = random.randint(60, 180)  # N√°hodn√© ƒçek√°n√≠ 1-3 minuty mezi dotazy
            print(f"‚è≥ ƒåek√°m {wait_time} sekund p≈ôed dotazem na profil @{username}...")
            time.sleep(wait_time)

            profile = instaloader.Profile.from_username(L.context, username)
            scraped_instagrams.add(username)  # P≈ôid√°me username do scrapnut√Ωch

            return {
                "full_name": profile.full_name,
                "followers": profile.followers,
                "following": profile.followees,
                "bio": profile.biography,
                "external_url": profile.external_url
            }

        except Exception as e:
            print(f"‚ùå Chyba p≈ôi z√≠sk√°v√°n√≠ profilu @{username} (pokus {attempt + 1}/{retries}): {e}")

            if "Please wait a few minutes" in str(e):
                wait_time = random.randint(600, 1200)  # ƒåekej 10-20 minut
                print(f"üö® Instagram limit, ƒçek√°m {wait_time} sekund p≈ôed dal≈°√≠m pokusem...")
                time.sleep(wait_time)
            else:
                return None  # Pokud je jin√° chyba, ukonƒçi smyƒçku hned

    return None  # Pokud sel≈æou v≈°echny pokusy, vra≈• None

#___________________________________________________________________________________________________________________
#                                                 WEBDRIVER SETTINGS
#___________________________________________________________________________________________________________________

# Seznam HTTP User-Agent z√°hlav√≠ pro maskov√°n√≠ po≈æadavk≈Ø, aby napodobovaly r≈Øzn√© prohl√≠≈æeƒçe
headers_list = [
    {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    },
    {
        "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko"
    },
    {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0"
    },
    {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15"
    },
    {
        "User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0"
    },
    {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1"
    },
    {
        "User-Agent": "Mozilla/5.0 (Linux; Android 11; SM-G981B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.210 Mobile Safari/537.36"
    },
    {
        "User-Agent": "Mozilla/5.0 (iPad; CPU OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1"
    },
    {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.48"
    },
    {
        "User-Agent": "Mozilla/5.0 (Linux; Android 10; SM-A505FN) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.105 Mobile Safari/537.36"
    }
]

# Nastaven√≠ mo≈ænost√≠ prohl√≠≈æeƒçe
options = Options()
options.add_argument("--headless")  
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-software-rasterizer")
options.add_argument("--ignore-certificate-errors")
options.add_argument("--disable-web-security")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--log-level=3")

# Nastaven√≠ n√°hodn√©ho User-Agenta
user_agent = random.choice(headers_list)
options.add_argument(f"user-agent={user_agent}")

# Inicializace prohl√≠≈æeƒçe Chrome
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# Extrakce u≈æivatelsk√©ho jm√©na z URL
def extract_username_from_url(url, site):
    url = clean_url(url)  # Nejprve oƒçist√≠me URL
    pattern = rf"{re.escape(site)}/([^/?#]+)"
    match = re.search(pattern, url)
    
    if match:
        username = match.group(1)
        # Filtrujeme neplatn√° u≈æivatelsk√° jm√©na
        if username.lower() not in ["login", "home", "settings", "explore", "company", "sharer", "intent", "help", "people", "accessibility", "recover", "watch", "policies", "legal", "public", "v", "_u", "blog", "about-us"]:
            return re.sub(r"[-\d]+$", "", username)  # Odstran√≠me koncov√© ƒç√≠sla/ID
    return None

#Funkce pro oƒçi≈°tƒõn√≠ URL od ne≈æ√°douc√≠ch parametr≈Ø
def clean_url(url):
    url = re.sub(r"(\?.*|#.*)", "", url)  # Odstran√≠me query parametry a kotvy
    return url


#___________________________________________________________________________________________________________________
#                                                       SCRAPER
#___________________________________________________________________________________________________________________


# Extrahuje data jako adresy, telefonn√≠ ƒç√≠sla, sportovn√≠ kluby, zamƒõstn√°n√≠ a soci√°ln√≠ profily
def scrape_information_from_url(url, name_to_search):
    try:
        print(f"Scraping: {url} with User-Agent: {user_agent}")  # Debug v√Ωpis

        driver.get(url)  
        time.sleep(3)  

        # Posunut√≠ str√°nky dol≈Ø pro naƒçten√≠ dynamick√©ho obsahu
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)  

        soup = BeautifulSoup(driver.page_source, 'html.parser')  

        # Extrahujeme text str√°nky a zajist√≠me, ≈æe nen√≠ None
        text = soup.get_text() if soup else ""

        # Inicializace sad pro ukl√°d√°n√≠ dat
        addresses = set()
        phone_numbers = set()
        sports_clubs = set()
        employment = set()
        social_profiles = set()

        # Seznam soci√°ln√≠ch s√≠t√≠ k detekci
        social_sites = ["linkedin.com", "facebook.com", "twitter.com", "instagram.com", "tiktok.com", "youtube.com"]
        temp_profiles = set()

        # Hled√°n√≠ odkaz≈Ø na soci√°ln√≠ s√≠tƒõ v HTML k√≥du
        for link in soup.find_all("a", href=True):  
            href = link["href"]
            link_text = link.get_text(strip=True) if link.get_text() else ""   

            for site in social_sites:
                if site in href:
                    username = extract_username_from_url(href, site)
                    if username:
                        temp_profiles.add(f"{site}/{username}")
                #Pokud URL neobsahuje u≈æivatelsk√© jm√©no, ale text odkazu ano
                elif site in link_text.lower():
                    temp_profiles.add(f"{site}/{link_text}")

        # Pou≈æit√≠ textu pro anal√Ωzu dal≈°√≠ch informac√≠
        for line in text.splitlines():
            line = line.strip()
            if name_to_search.lower() in line.lower():
                if "address" in line.lower():
                    addresses.add(line)
                if "phone" in line.lower():
                    phone_numbers.add(line)
                if "club" in line.lower():
                    sports_clubs.add(line)
                if "job" in line.lower():
                    employment.add(line)

        # Odstran√≠me mo≈æn√© duplik√°ty na z√°kladƒõ u≈æivatelsk√©ho jm√©na
        unique_profiles = set()
        for profile in temp_profiles:
            base_profile = re.sub(r"[-\d]+$", "", profile)  # Odstran√≠ ƒç√≠sla na konci
            unique_profiles.add(base_profile)

        # Se≈ôazen√≠ podle dom√©ny
        sorted_profiles = sorted(unique_profiles, key=lambda x: (x.split('/')[0], x.split('/')[1] if '/' in x else ""))
        # Odstranƒõn√≠ doublov√°n√≠
        social_profiles.update(sorted_profiles)  # Ulo≈æ√≠me jen unik√°tn√≠ profily

        # Informace z Instaloaderu Instagramu
        instagram_details = {}
        for profile in social_profiles:
            if "instagram.com" in profile:
                username = extract_instagram_username(profile)
                if username:
                    details = get_instagram_profile_details(username)
                    if details:
                        instagram_details[username] = details

        return {
            'addresses': addresses,
            'phone_numbers': phone_numbers,
            'sports_clubs': sports_clubs,
            'employment': employment,
            'social_profiles': social_profiles
        }
    except Exception as e:
        print(f"Error accessing {url}: {e}")
        return {
            'addresses': set(),
            'phone_numbers': set(),
            'sports_clubs': set(),
            'employment': set(),
            'social_profiles': set()
        }

#___________________________________________________________________________________________________________________
#                                                   SEARCH
#___________________________________________________________________________________________________________________


# Vyhled√°n√≠ informac√≠ na DuckDuckGo
def search_duckduckgo(query):
    try:
        with DDGS() as ddgs:
            results = [r['href'] for r in ddgs.text(query, max_results=10)]
        return results
    except Exception as e:
        print(f'Error during DuckDuckGo search: {e}')
        return []

# Vytvo≈ôen√≠ variant jmen pro vyhled√°v√°n√≠
def generate_name_variants(extracted_name):
    """
    Vytvo≈ô√≠ r≈Øzn√© kombinace jm√©na a p≈ô√≠jmen√≠ pro vyhled√°v√°n√≠.

    :param extracted_name: Jm√©no ve form√°tu "Jm√©no P≈ô√≠jmen√≠".
    :return: Seznam variant jm√©na pro vyhled√°v√°n√≠.
    """
    if not extracted_name or len(extracted_name.split()) != 2:
        return []

    first_name, last_name = extracted_name.split()

    # Odstranƒõn√≠ mezer a diakritiky pro variace
    first_name = remove_diacritics(first_name).lower()
    last_name = remove_diacritics(last_name).lower()

    variants = [
        f"{first_name}{last_name}",
        f"{first_name}.{last_name}",
        f"{first_name}_{last_name}",
        f"{last_name}{first_name}",
        f"{last_name}.{first_name}",
        f"{last_name}_{first_name}"
    ]
    return variants


#___________________________________________________________________________________________________________________
#                                                       MAIN
#___________________________________________________________________________________________________________________



if __name__ == "__main__":
    email_query = input("Zadejte e-mail nebo kl√≠ƒçov√© slovo pro hled√°n√≠: ")
    extracted_name = extract_name_from_email(email_query)
    print(f'Lok√°ln√≠ ƒç√°st e-mailu: {email_query.split("@")[0]}')  # Debug v√Ωpis lok√°ln√≠ ƒç√°sti e-mailu
    if extracted_name:
        print(f'Extrahovan√© jm√©no z e-mailu: {extracted_name}')
    else:
        print('Jm√©no nebylo extrahov√°no z e-mailu.')
    # Anal√Ωza jm√©na na z√°kladƒõ slovn√≠ku
    if extracted_name:
        if is_name_in_dictionary(extracted_name.split()[0]):
            print(f'Jm√©no "{extracted_name.split()[0]}" bylo nalezeno ve slovn√≠ku.')
        else:
            print(f'Jm√©no "{extracted_name.split()[0]}" nebylo nalezeno ve slovn√≠ku.')
    if extracted_name:
        name_variants = generate_name_variants(extracted_name)
        print("Vygenerovan√© varianty jm√©na:")
        for variant in name_variants:
            print(variant)
            query_name = variant
        print(f'Vyhled√°v√°m informace pro extrahovan√© jm√©no: {extracted_name}')
    else:
        query_name = email_query
        print(f'Vyhled√°v√°m informace pro e-mail: {query_name}')

    # Vyhled√°v√°n√≠ informac√≠ o osobƒõ spjat√© s t√≠mto e-mailem
    search_results = []
    if extracted_name:
        for variant in name_variants:
            search_results.extend(search_duckduckgo(variant))
    else:
        search_results = search_duckduckgo(query_name)
    
    print("DuckDuckGo Results:", search_results) # Debug info

    if not search_results:
        print('No search results found')
    else:
        all_addresses = set()
        all_phone_numbers = set()
        all_sports_clubs = set()
        all_employment = set()
        all_social_profiles = set()
        all_instagram_details = {}

        for link in search_results:
            print(f"Scraping data from: {link}")  # Debug info
            info = scrape_information_from_url(link, query_name)
            all_addresses.update(info['addresses'])
            all_phone_numbers.update(info['phone_numbers'])
            all_sports_clubs.update(info['sports_clubs'])
            all_employment.update(info['employment'])
            all_social_profiles.update(info['social_profiles'])
            if 'instagram_details' in info:
                all_instagram_details.update(info['instagram_details'])


        # V√Ωpis nalezen√Ωch informac√≠
        print('\nNalezen√© informace:')
        if all_addresses:
            print('\nüìç Adresy:')
            for address in all_addresses:
                print(address)
        if all_phone_numbers:
            print('\nüìû Telefonn√≠ ƒç√≠sla:')
            for number in all_phone_numbers:
                print(number)
        if all_sports_clubs:
            print('\n‚öΩ Sportovn√≠ kluby:')
            for club in all_sports_clubs:
                print(club)
        if all_employment:
            print('\nüíº Zamƒõstn√°n√≠:')
            for job in all_employment:
                print(job)
        if all_social_profiles:
            print('\nüåç Soci√°ln√≠ profily:')
            for profile in all_social_profiles:
                print(profile)

        if all_instagram_details:
            print('\nüì∏ Detailn√≠ informace z Instagramu:')
            for username, details in all_instagram_details.items():
                print(f"\nüîπ Instagram: @{username}")
                print(f"   üìõ Jm√©no: {details['full_name']}")
                print(f"   üë• Sleduj√≠c√≠: {details['followers']}")
                print(f"   üéØ Sleduje: {details['following']}")
                print(f"   üìù Bio: {details['bio']}")
                print(f"   üîó Odkaz v bio: {details['external_url']}")

        if not (all_addresses or all_phone_numbers or all_sports_clubs or all_employment or all_social_profiles):
            print('≈Ω√°dn√© informace nebyly nalezeny.')

    # Ukonƒçen√≠ Selenium WebDriveru na konci programu
    driver.quit()
